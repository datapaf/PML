{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WpIeeeM1J6u"
      },
      "source": [
        "# ELMo: Embeddings from Language Models \n",
        "<!-- ![](https://get.whotrades.com/u4/photoDE6C/20647654315-0/blogpost.jpeg) -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjrI02kE2Zfr"
      },
      "source": [
        "In this assignment you will implement a deep lstm-based model for contextualized word embeddings - ELMo. Your tasks are as following: \n",
        "\n",
        "- Preprocessing (20 points)\n",
        "- Implementation of ELMo model (30 points)\n",
        "  - 2-layer BiLSTM (15 points)\n",
        "  - Highway layers (5 points) [link](https://paperswithcode.com/method/highway-layer) [paper](https://arxiv.org/pdf/1507.06228.pdf) [code](https://github.com/allenai/allennlp/blob/9f879b0964e035db711e018e8099863128b4a46f/allennlp/modules/highway.py#L11)\n",
        "  - CharCNN embeddings (5 points) [paper](https://arxiv.org/pdf/1509.01626.pdf)\n",
        "  - Handle out-of-vocabulary words (5 points)\n",
        "- Report metrics and loss using tensorbord/comet or other tool.  (10 points)\n",
        "- Evaluate on movie review dataset (20 pts)\n",
        "- Compare the performance with BERT model (10 pts)\n",
        "- Clean and documented code (10 points)\n",
        "\n",
        "\n",
        "Remarks: \n",
        "\n",
        "*   Use Pytorch\n",
        "*   Cheating will result in 0 points\n",
        "\n",
        "\n",
        "ELMo paper: https://arxiv.org/pdf/1802.05365.pdf\n",
        "\n",
        "Possible datasets:\n",
        "- [WikiText-103](https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/)\n",
        "- Any monolingual dataset from [WMT](https://statmt.org/wmt22/translation-task.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoFWzNeaTOTu"
      },
      "source": [
        "## Data loading and preprocessing\n",
        "Preprocess the english monolingual data (20 points):\n",
        "- clean\n",
        "- split to train and validation\n",
        "- tokenize\n",
        "- create vocabulary, convert words to numbers. [vocab](https://pytorch.org/text/stable/vocab.html#id1)\n",
        "- pad sequences\n",
        "\n",
        "Use these tutorials [one](https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html) and [two](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html) as a reference\n",
        "\n",
        "![](https://miro.medium.com/max/720/1*UPirqwpBWnNmcwoUjfZZIA.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       ' 1979 standup tour. citation In 1998, he rele...\n",
              "1       A 100-year-old woman named Rose DeWitt Bukater...\n",
              "2       A1 is the name of a major road in some countries.\n",
              "3       A 2002 report by American Sports Data found th...\n",
              "4                   A 268-page booklet available on-line.\n",
              "                              ...                        \n",
              "9555    Zones are the places where buildings can develop.\n",
              "9556    Zoological Journal of the Linnean Society, 71,...\n",
              "9557    Zou Tribe is one of the Schedule Tribes of Man...\n",
              "9558    Zubeyr was killed in a U.S. drone airstrike on...\n",
              "9559    Քաշաթաղի մելիքություն) - Armenian melikdom(pri...\n",
              "Name: 1, Length: 9560, dtype: object"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_dir = 'eng-simple_wikipedia_2021_10K'\n",
        "data_filename = \"eng-simple_wikipedia_2021_10K-sentences.txt\"\n",
        "data_full_filename = os.path.join(data_dir, data_filename)\n",
        "\n",
        "# read data_ful_filename into a pandas dataframe without index\n",
        "sents = pd.read_csv(data_full_filename, sep='\\t', header=None, index_col=False)[1]\n",
        "sents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filter ASCII-only Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       ' 1979 standup tour. citation In 1998, he rele...\n",
              "1       A 100-year-old woman named Rose DeWitt Bukater...\n",
              "2       A1 is the name of a major road in some countries.\n",
              "3       A 2002 report by American Sports Data found th...\n",
              "4                   A 268-page booklet available on-line.\n",
              "                              ...                        \n",
              "9554                                  Z is not used much.\n",
              "9555    Zones are the places where buildings can develop.\n",
              "9556    Zoological Journal of the Linnean Society, 71,...\n",
              "9557    Zou Tribe is one of the Schedule Tribes of Man...\n",
              "9558    Zubeyr was killed in a U.S. drone airstrike on...\n",
              "Name: 1, Length: 8969, dtype: object"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ascii_sent_indices = np.array(list(map(lambda x: x.isascii(), sents)))\n",
        "ascii_sents = sents[ascii_sent_indices]\n",
        "ascii_sents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train-Test Indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split sentences into train and test sets with numpy\n",
        "np.random.seed(42)\n",
        "train_indices = np.random.choice(ascii_sents.index, size=int(0.8*len(ascii_sents)), replace=False)\n",
        "test_indices = ascii_sents.index.difference(train_indices)\n",
        "# train_sents = ascii_sents.loc[train_indices]\n",
        "# test_sents = ascii_sents.loc[test_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "# create pytorch tokenizer\n",
        "tokenizer = get_tokenizer('basic_english')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Word Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create vocabulary of training words\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "vocab = build_vocab_from_iterator(\n",
        "    [tokenizer(sent) for sent in train_sents],\n",
        "    specials=['<unk>', '<pad>', '<bos>', '<eos>']\n",
        ")\n",
        "\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Char Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create vocabulary of ascii symbols\n",
        "ascii_symbols = list(map(chr, range(127)))\n",
        "\n",
        "symbols_vocab = build_vocab_from_iterator(\n",
        "    [ascii_symbols],\n",
        "    specials=['<unk>', '<pad>', '<bos>', '<eos>']\n",
        ")\n",
        "\n",
        "symbols_vocab.set_default_index(symbols_vocab['<unk>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenized Sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tokenize ascii_sents\n",
        "tokenized_sents = list(map(tokenizer, ascii_sents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Max Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get max number of words in tokenized_sents\n",
        "max_num_words = max(map(lambda x: len(x), tokenized_sents))\n",
        "max_num_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Max Letters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get max number of letters in the words in tokenized_sents\n",
        "max_num_letters = max(map(lambda x: max(map(lambda y: len(y), x)), tokenized_sents))\n",
        "max_num_letters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Padded Word Ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8969, 571])"
            ]
          },
          "execution_count": 227,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# padded_word_ids = torch.full(\n",
        "#     size=(len(ascii_sents), max_num_words),\n",
        "#     fill_value=vocab['<pad>']\n",
        "# )\n",
        "# padded_word_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for sent_num, sent in enumerate(tokenized_sents):\n",
        "#     for word_num, word in enumerate(sent):\n",
        "#         padded_word_ids[sent_num, word_num] = vocab[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sents_to_word_ids(sents):\n",
        "    word_ids = []\n",
        "    for sent in sents:\n",
        "        sent_word_ids = [vocab['<bos>']] + [vocab[token] for token in tokenizer(sent)] + [vocab['<eos>']]\n",
        "        word_ids.append(torch.Tensor(sent_word_ids))\n",
        "    return word_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.0000e+00, 1.8000e+01, 1.1870e+03,  ..., 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00],\n",
              "        [2.0000e+00, 1.0000e+01, 6.6030e+03,  ..., 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00],\n",
              "        [2.0000e+00, 7.1350e+03, 1.2000e+01,  ..., 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00],\n",
              "        ...,\n",
              "        [2.0000e+00, 0.0000e+00, 1.7630e+03,  ..., 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00],\n",
              "        [2.0000e+00, 6.5600e+03, 3.1630e+03,  ..., 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00],\n",
              "        [2.0000e+00, 1.6338e+04, 1.3000e+01,  ..., 1.0000e+00, 1.0000e+00,\n",
              "         1.0000e+00]])"
            ]
          },
          "execution_count": 236,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_ids = sents_to_word_ids(ascii_sents)\n",
        "#print(word_ids[:2])\n",
        "padded_word_ids = torch.nn.utils.rnn.pad_sequence(word_ids, padding_value=vocab['<pad>'], batch_first=True)\n",
        "padded_word_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BATCH_SIZE = 128\n",
        "\n",
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# def pad_batch(data_batch):\n",
        "#     return pad_sequence(data_batch, padding_value=vocab['<pad>'])\n",
        "\n",
        "# train_iter = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
        "# test_iter = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Padded Char Ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8969, 571, 35])"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_char_ids = torch.full(\n",
        "    size=(len(ascii_sents), max_num_words, max_num_letters),\n",
        "    fill_value=symbols_vocab['<pad>']\n",
        ")\n",
        "padded_char_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "for sent_num, sent in enumerate(ascii_sents):\n",
        "    for word_num, word in enumerate(tokenizer(sent)):\n",
        "        for letter_num, letter in enumerate(word):\n",
        "            padded_char_ids[sent_num, word_num, letter_num] = symbols_vocab[letter]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 43,   1,   1,  ...,   1,   1,   1],\n",
              "         [ 53,  61,  59,  ...,   1,   1,   1],\n",
              "         [119, 120, 101,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1]],\n",
              "\n",
              "        [[101,   1,   1,  ...,   1,   1,   1],\n",
              "         [ 53,  52,  52,  ...,   1,   1,   1],\n",
              "         [123, 115, 113,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1]],\n",
              "\n",
              "        [[101,  53,   1,  ...,   1,   1,   1],\n",
              "         [109, 119,   1,  ...,   1,   1,   1],\n",
              "         [120, 108, 105,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[126, 115, 115,  ...,   1,   1,   1],\n",
              "         [110, 115, 121,  ...,   1,   1,   1],\n",
              "         [115, 106,   1,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1]],\n",
              "\n",
              "        [[126, 115, 121,  ...,   1,   1,   1],\n",
              "         [120, 118, 109,  ...,   1,   1,   1],\n",
              "         [109, 119,   1,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1]],\n",
              "\n",
              "        [[126, 121, 102,  ...,   1,   1,   1],\n",
              "         [123, 101, 119,  ...,   1,   1,   1],\n",
              "         [111, 109, 112,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1]]])"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_char_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6_05j-_TR76"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "# from torchtext.vocab import vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU_JDeZ6TTx2"
      },
      "source": [
        "## Model - learning embeddings\n",
        "Read chapter 3 from the [paper](https://arxiv.org/pdf/1802.05365.pdf)\n",
        "\n",
        "Implement this model with \n",
        "- 2 BiLSTM layers,\n",
        "- CharCNN embeddings,\n",
        "- Highway layers,\n",
        "- out-of-vocabulary words handling\n",
        "\n",
        "Plot the training and validation losses over the epochs (iterations)\n",
        "\n",
        "Use the [implementation](https://github.com/allenai/allennlp/blob/main/allennlp/modules/elmo.py) as a reference\n",
        "\n",
        "![](https://miro.medium.com/max/720/1*3_wsDpyNG-TylsRACF48yA.png)\n",
        "\n",
        "![](https://miro.medium.com/max/720/1*8pG54o28pbD2L0dv5THL-A.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class ELMo(nn.Module):\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        n_tokens,\n",
        "        n_chars=50,\n",
        "        embedding_dim=4,\n",
        "        #projection_dim=512,\n",
        "        lstm_units=4096,\n",
        "        elmo_output_size=512\n",
        "    ):\n",
        "        super(ELMo, self).__init__()\n",
        "        \n",
        "        self.vocab_size = vocab_size\n",
        "        self.n_tokens = n_tokens\n",
        "        self.n_chars = n_chars\n",
        "        self.embedding_dim = embedding_dim\n",
        "        #self.projection_dim = projection_dim\n",
        "        self.lstm_units = lstm_units\n",
        "        self.elmo_output_size = elmo_output_size\n",
        "        \n",
        "\n",
        "        self.embedding_matrix = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        filters = [[1,4], [2,8], [3,26], [4,32], [5,64]]\n",
        "        self.conv_layers = nn.ModuleList([\n",
        "            nn.Conv1d(\n",
        "                in_channels=4,\n",
        "                out_channels=num,\n",
        "                kernel_size=width,\n",
        "                bias=True \n",
        "            )\n",
        "            for (width, num) in filters\n",
        "        ])\n",
        "        self.conv_activation = nn.ReLU()\n",
        "\n",
        "        self.highway_layers = nn.ModuleList([\n",
        "            nn.Linear(134, 134 * 2)\n",
        "            for _ in range(2)\n",
        "        ])\n",
        "        self.highway_activation = nn.ReLU()\n",
        "        self.highway_projection = nn.Linear(134, elmo_output_size, bias=True)\n",
        "        \n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=elmo_output_size,\n",
        "            hidden_size=lstm_units,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            num_layers=2,\n",
        "            proj_size=elmo_output_size\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Linear(2 * elmo_output_size, vocab_size, bias=True)\n",
        "\n",
        "        # self.lstm2 = nn.LSTM(\n",
        "        #     input_size=elmo_output_size,\n",
        "        #     hidden_size=lstm_units,\n",
        "        #     bidirectional=True,\n",
        "        #     batch_first=True,\n",
        "        #     proj_size=elmo_output_size\n",
        "        # )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        print(x.shape)\n",
        "\n",
        "        # embed the input\n",
        "        # in shape: (batch_size, n_tokens, n_chars)\n",
        "        # out shape: (batch_size, n_tokens, n_chars, embedding_dim)\n",
        "        embedded = self.embedding_matrix(x.view(-1, self.n_chars))\n",
        "\n",
        "        print(embedded.shape)\n",
        "\n",
        "        # CharCNN\n",
        "        # in shape: (n_tokens, n_chars, embedding_dim)\n",
        "        # out shape: (n_tokens, projection_dim)\n",
        "\n",
        "        embedded = torch.transpose(embedded, 1, 2)\n",
        "\n",
        "        # pass the embedded input through the convolutional layers\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv_output = conv_layer(embedded)\n",
        "            conv_output, _ = torch.max(conv_output, dim=-1)\n",
        "            conv_output = self.conv_activation(conv_output)\n",
        "            conv_outputs.append(conv_output)\n",
        "\n",
        "        # concatenate the conv outputs\n",
        "        token_embedding = torch.cat(conv_outputs, dim=-1)\n",
        "\n",
        "        print(token_embedding.shape)\n",
        "\n",
        "        # pass the conv output through the highway layers\n",
        "        highway_output = token_embedding\n",
        "        for highway_layer in self.highway_layers:\n",
        "            projected_input = highway_layer(highway_output)\n",
        "            linear_part = highway_output\n",
        "\n",
        "            nonlinear_part, gate = projected_input.chunk(2, dim=-1)\n",
        "            nonlinear_part = self.highway_activation(nonlinear_part)\n",
        "            gate = torch.sigmoid(gate)\n",
        "\n",
        "            highway_output = gate * linear_part + (1 - gate) * nonlinear_part\n",
        "        \n",
        "        token_embedding = self.highway_projection(highway_output) \n",
        "\n",
        "        print(token_embedding.shape)\n",
        "\n",
        "        # pass the token embedding through the BiLSTM\n",
        "        lstm_output, _ = self.lstm(token_embedding)\n",
        "\n",
        "        out = self.linear(lstm_output)\n",
        "\n",
        "        return out\n",
        "\n",
        "        lstm2_output = self.lstm2(lstm1_output)\n",
        "\n",
        "        # return lstm2_output, lstm1_output, token_embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 571, 35])\n",
            "torch.Size([1713, 35, 4])\n",
            "torch.Size([1713, 134])\n",
            "torch.Size([1713, 512])\n"
          ]
        }
      ],
      "source": [
        "model = ELMo(vocab_size=len(vocab), n_tokens=max_num_words, n_chars=max_num_letters)\n",
        "pred = model(padded_char_ids[0:3, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.0021,  0.0262, -0.0112,  ...,  0.0107, -0.0050, -0.0005],\n",
              "        [-0.0018,  0.0261, -0.0108,  ...,  0.0100, -0.0050, -0.0012],\n",
              "        [-0.0016,  0.0261, -0.0107,  ...,  0.0097, -0.0049, -0.0016],\n",
              "        ...,\n",
              "        [-0.0011,  0.0263, -0.0102,  ...,  0.0096, -0.0051, -0.0018],\n",
              "        [-0.0010,  0.0264, -0.0104,  ...,  0.0095, -0.0052, -0.0016],\n",
              "        [-0.0006,  0.0268, -0.0106,  ...,  0.0093, -0.0055, -0.0011]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 223,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1713, 16340])"
            ]
          },
          "execution_count": 224,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16340"
            ]
          },
          "execution_count": 225,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train the model\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i in range(0, len(padded_char_ids), 32):\n",
        "        # get the inputs\n",
        "        inputs = padded_char_ids[i:i+32, :, :]\n",
        "        labels = padded_ids[i:i+32, :]\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.view(-1, len(vocab)), labels.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 32 == 31:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 32))\n",
        "            running_loss = 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ4HsuafA5sQ"
      },
      "source": [
        "## Evaluate your embeddings model on IMDB movie reviews dataset (sentiment analysis) \n",
        "[Dataset](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)\n",
        "\n",
        "Preprocess data\n",
        "\n",
        "Disable training for ELMo, it will produce 5 embeddings for each word, add trainable parameters $\\gamma^{task}$ and $s^{task}_j$\n",
        "\n",
        "Don't forget metric plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQ_0LTQf81CM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKhTvahJBcBI"
      },
      "source": [
        "## Compare the results with BERT embeddings\n",
        "you can choose other bert model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCojr57Zov7t"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "454c98ae2731e865a69a0b883f25a1cfa6b0f63785a62bbc0572ffd435d4c747"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
