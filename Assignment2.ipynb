{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WpIeeeM1J6u"
      },
      "source": [
        "# ELMo: Embeddings from Language Models \n",
        "<!-- ![](https://get.whotrades.com/u4/photoDE6C/20647654315-0/blogpost.jpeg) -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjrI02kE2Zfr"
      },
      "source": [
        "In this assignment you will implement a deep lstm-based model for contextualized word embeddings - ELMo. Your tasks are as following: \n",
        "\n",
        "- Preprocessing (20 points)\n",
        "- Implementation of ELMo model (30 points)\n",
        "  - 2-layer BiLSTM (15 points)\n",
        "  - Highway layers (5 points) [link](https://paperswithcode.com/method/highway-layer) [paper](https://arxiv.org/pdf/1507.06228.pdf) [code](https://github.com/allenai/allennlp/blob/9f879b0964e035db711e018e8099863128b4a46f/allennlp/modules/highway.py#L11)\n",
        "  - CharCNN embeddings (5 points) [paper](https://arxiv.org/pdf/1509.01626.pdf)\n",
        "  - Handle out-of-vocabulary words (5 points)\n",
        "- Report metrics and loss using tensorbord/comet or other tool.  (10 points)\n",
        "- Evaluate on movie review dataset (20 pts)\n",
        "- Compare the performance with BERT model (10 pts)\n",
        "- Clean and documented code (10 points)\n",
        "\n",
        "\n",
        "Remarks: \n",
        "\n",
        "*   Use Pytorch\n",
        "*   Cheating will result in 0 points\n",
        "\n",
        "\n",
        "ELMo paper: https://arxiv.org/pdf/1802.05365.pdf\n",
        "\n",
        "Possible datasets:\n",
        "- [WikiText-103](https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/)\n",
        "- Any monolingual dataset from [WMT](https://statmt.org/wmt22/translation-task.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoFWzNeaTOTu"
      },
      "source": [
        "## Data loading and preprocessing\n",
        "Preprocess the english monolingual data (20 points):\n",
        "- clean\n",
        "- split to train and validation\n",
        "- tokenize\n",
        "- create vocabulary, convert words to numbers. [vocab](https://pytorch.org/text/stable/vocab.html#id1)\n",
        "- pad sequences\n",
        "\n",
        "Use these tutorials [one](https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html) and [two](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html) as a reference\n",
        "\n",
        "![](https://miro.medium.com/max/720/1*UPirqwpBWnNmcwoUjfZZIA.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\datapaf\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       ' 1979 standup tour. citation In 1998, he rele...\n",
              "1       A 100-year-old woman named Rose DeWitt Bukater...\n",
              "2       A1 is the name of a major road in some countries.\n",
              "3       A 2002 report by American Sports Data found th...\n",
              "4                   A 268-page booklet available on-line.\n",
              "                              ...                        \n",
              "9555    Zones are the places where buildings can develop.\n",
              "9556    Zoological Journal of the Linnean Society, 71,...\n",
              "9557    Zou Tribe is one of the Schedule Tribes of Man...\n",
              "9558    Zubeyr was killed in a U.S. drone airstrike on...\n",
              "9559    Քաշաթաղի մելիքություն) - Armenian melikdom(pri...\n",
              "Name: 1, Length: 9560, dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_dir = 'eng-simple_wikipedia_2021_10K'\n",
        "data_filename = \"eng-simple_wikipedia_2021_10K-sentences.txt\"\n",
        "data_full_filename = os.path.join(data_dir, data_filename)\n",
        "\n",
        "# read data_ful_filename into a pandas dataframe without index\n",
        "sents = pd.read_csv(data_full_filename, sep='\\t', header=None, index_col=False)[1]\n",
        "sents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filter ASCII-only Sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       ' 1979 standup tour. citation In 1998, he rele...\n",
              "1       A 100-year-old woman named Rose DeWitt Bukater...\n",
              "2       A1 is the name of a major road in some countries.\n",
              "3       A 2002 report by American Sports Data found th...\n",
              "4                   A 268-page booklet available on-line.\n",
              "                              ...                        \n",
              "8964                                  Z is not used much.\n",
              "8965    Zones are the places where buildings can develop.\n",
              "8966    Zoological Journal of the Linnean Society, 71,...\n",
              "8967    Zou Tribe is one of the Schedule Tribes of Man...\n",
              "8968    Zubeyr was killed in a U.S. drone airstrike on...\n",
              "Name: 1, Length: 8969, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ascii_sent_indices = np.array(list(map(lambda x: x.isascii(), sents)))\n",
        "ascii_sents = sents[ascii_sent_indices]\n",
        "ascii_sents = ascii_sents.reset_index(drop=True)\n",
        "ascii_sents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train-Test Indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split sentences into train and test sets with numpy\n",
        "np.random.seed(42)\n",
        "train_indices = np.random.choice(ascii_sents.index, size=int(0.8*len(ascii_sents)), replace=False)\n",
        "test_indices = ascii_sents.index.difference(train_indices)\n",
        "train_sents = ascii_sents.loc[train_indices]\n",
        "test_sents = ascii_sents.loc[test_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "# create pytorch tokenizer\n",
        "tokenizer = get_tokenizer('basic_english')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Word Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create vocabulary of training words\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "vocab = build_vocab_from_iterator(\n",
        "    [tokenizer(sent) for sent in train_sents],\n",
        "    specials=['<unk>', '<pad>', '<bos>', '<eos>']\n",
        ")\n",
        "\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Char Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create vocabulary of ascii symbols\n",
        "ascii_symbols = list(map(chr, range(127)))\n",
        "\n",
        "symbols_vocab = build_vocab_from_iterator(\n",
        "    [ascii_symbols],\n",
        "    specials=['<unk>', '<pad>', '<bow>', '<eow>']\n",
        ")\n",
        "\n",
        "symbols_vocab.set_default_index(symbols_vocab['<unk>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenized Sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tokenize ascii_sents\n",
        "tokenized_sents = list(map(tokenizer, ascii_sents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Max Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "571"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get max number of words in tokenized_sents\n",
        "max_num_words = max(map(lambda x: len(x), tokenized_sents))\n",
        "max_num_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Max Letters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get max number of letters in the words in tokenized_sents\n",
        "max_num_letters = max(map(lambda x: max(map(lambda y: len(y), x)), tokenized_sents))\n",
        "max_num_letters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Padded Word Ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sents_to_word_ids(sents):\n",
        "    word_ids = []\n",
        "    for sent in sents:\n",
        "        sent_word_ids = torch.tensor([vocab['<bos>']] + [vocab[token] for token in tokenizer(sent)] + [vocab['<eos>']])\n",
        "        word_ids.append(sent_word_ids)\n",
        "    return word_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([    2,    18,  1187, 14913,   979,     4,   104,     8,   689,     6,\n",
              "            15,   103,  4593,  1159,     6,    10,  2233,   181,     4,     3]),\n",
              " tensor([    2,    10,  6603,   388,   178,  1826,  9339,  8270,  1067,    10,\n",
              "           302,    63,    49, 15982,    19,     5,   307,  1166, 15466,     4,\n",
              "             3])]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_ids = sents_to_word_ids(ascii_sents)\n",
        "word_ids[:2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[    2,    18,  1187,  ...,     1,     1,     1],\n",
              "        [    2,    10,  6603,  ...,     1,     1,     1],\n",
              "        [    2,  7135,    12,  ...,     1,     1,     1],\n",
              "        ...,\n",
              "        [    2,     0,  1763,  ...,     1,     1,     1],\n",
              "        [    2,  6560,  3163,  ...,     1,     1,     1],\n",
              "        [    2, 16338,    13,  ...,     1,     1,     1]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_word_ids = torch.nn.utils.rnn.pad_sequence(word_ids, padding_value=vocab['<pad>'], batch_first=True)\n",
        "padded_word_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8969, 573])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_word_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# padded_word_ids = padded_word_ids.to(device)\n",
        "# padded_word_ids.get_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BATCH_SIZE = 128\n",
        "\n",
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# def pad_batch(data_batch):\n",
        "#     return pad_sequence(data_batch, padding_value=vocab['<pad>'])\n",
        "\n",
        "# train_iter = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)\n",
        "# test_iter = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Padded Char Ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8969, 573, 35])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_char_ids = torch.full(\n",
        "    size=(len(ascii_sents), max_num_words + 2, max_num_letters),\n",
        "    fill_value=symbols_vocab['<pad>']\n",
        ")\n",
        "padded_char_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "for sent_num, sent in enumerate(ascii_sents):\n",
        "    tokenized = tokenizer(sent)\n",
        "    for i in range(0, len(tokenized) + 2):\n",
        "        if i == 0:\n",
        "            padded_char_ids[sent_num, i, 0] = symbols_vocab['<bow>']\n",
        "            padded_char_ids[sent_num, i, 1] = symbols_vocab['<bos>']\n",
        "            padded_char_ids[sent_num, i, 2] = symbols_vocab['<eow>']\n",
        "            continue\n",
        "        elif i == len(tokenized) + 1:\n",
        "            padded_char_ids[sent_num, i, 0] = symbols_vocab['<bow>']\n",
        "            padded_char_ids[sent_num, i, 1] = symbols_vocab['<eos>']\n",
        "            padded_char_ids[sent_num, i, 2] = symbols_vocab['<eow>']\n",
        "            continue\n",
        "        word = tokenized[i - 1]\n",
        "        for letter_num, letter in enumerate(word):\n",
        "            padded_char_ids[sent_num, i, letter_num] = symbols_vocab[letter]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "symbols_vocab['.']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[  2,   0,   3,  ...,   1,   1,   1],\n",
              "         [ 43,   1,   1,  ...,   1,   1,   1],\n",
              "         [ 53,  61,  59,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1]],\n",
              "\n",
              "        [[  2,   0,   3,  ...,   1,   1,   1],\n",
              "         [101,   1,   1,  ...,   1,   1,   1],\n",
              "         [ 53,  52,  52,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1]],\n",
              "\n",
              "        [[  2,   0,   3,  ...,   1,   1,   1],\n",
              "         [101,  53,   1,  ...,   1,   1,   1],\n",
              "         [109, 119,   1,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[  2,   0,   3,  ...,   1,   1,   1],\n",
              "         [126, 115, 115,  ...,   1,   1,   1],\n",
              "         [110, 115, 121,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1]],\n",
              "\n",
              "        [[  2,   0,   3,  ...,   1,   1,   1],\n",
              "         [126, 115, 121,  ...,   1,   1,   1],\n",
              "         [120, 118, 109,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1]],\n",
              "\n",
              "        [[  2,   0,   3,  ...,   1,   1,   1],\n",
              "         [126, 121, 102,  ...,   1,   1,   1],\n",
              "         [123, 101, 119,  ...,   1,   1,   1],\n",
              "         ...,\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1],\n",
              "         [  1,   1,   1,  ...,   1,   1,   1]]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_char_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8969, 573, 35])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_char_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# padded_char_ids = padded_char_ids.to(device)\n",
        "# padded_char_ids.get_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "f6_05j-_TR76"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import TensorDataset, DataLoader\n",
        "# from torchtext.vocab import vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create dataset from padded_word_ids and padded_char_ids\n",
        "\n",
        "# import TensorDataset\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "train_ds = TensorDataset(padded_word_ids[train_indices], padded_char_ids[train_indices])\n",
        "test_ds = TensorDataset(padded_word_ids[test_indices], padded_char_ids[test_indices])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create dataloaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_iter = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_iter = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU_JDeZ6TTx2"
      },
      "source": [
        "## Model - learning embeddings\n",
        "Read chapter 3 from the [paper](https://arxiv.org/pdf/1802.05365.pdf)\n",
        "\n",
        "Implement this model with \n",
        "- 2 BiLSTM layers,\n",
        "- CharCNN embeddings,\n",
        "- Highway layers,\n",
        "- out-of-vocabulary words handling\n",
        "\n",
        "Plot the training and validation losses over the epochs (iterations)\n",
        "\n",
        "Use the [implementation](https://github.com/allenai/allennlp/blob/main/allennlp/modules/elmo.py) as a reference\n",
        "\n",
        "![](https://miro.medium.com/max/720/1*3_wsDpyNG-TylsRACF48yA.png)\n",
        "\n",
        "![](https://miro.medium.com/max/720/1*8pG54o28pbD2L0dv5THL-A.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class ELMo(nn.Module):\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        n_tokens,\n",
        "        n_chars=50,\n",
        "        embedding_dim=4,\n",
        "        lstm_units=256,\n",
        "        elmo_output_size=32\n",
        "    ):\n",
        "        super(ELMo, self).__init__()\n",
        "        \n",
        "        self.vocab_size = vocab_size\n",
        "        self.n_tokens = n_tokens\n",
        "        self.n_chars = n_chars\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lstm_units = lstm_units\n",
        "        self.elmo_output_size = elmo_output_size\n",
        "        \n",
        "\n",
        "        self.embedding_matrix = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        filters = [[1,4], [2,8], [3,26], [4,32], [5,64]]\n",
        "        self.conv_layers = nn.ModuleList([\n",
        "            nn.Conv1d(\n",
        "                in_channels=4,\n",
        "                out_channels=num,\n",
        "                kernel_size=width,\n",
        "                bias=True \n",
        "            )\n",
        "            for (width, num) in filters\n",
        "        ])\n",
        "        self.conv_activation = nn.ReLU()\n",
        "\n",
        "        self.highway_layers = nn.ModuleList([\n",
        "            nn.Linear(134, 134 * 2)\n",
        "            for _ in range(2)\n",
        "        ])\n",
        "        self.highway_activation = nn.ReLU()\n",
        "        self.highway_projection = nn.Linear(134, elmo_output_size, bias=True)\n",
        "        \n",
        "        self.lstm1 = nn.LSTM(\n",
        "            input_size=elmo_output_size,\n",
        "            hidden_size=lstm_units,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            proj_size=elmo_output_size\n",
        "        )\n",
        "\n",
        "        self.lstm2 = nn.LSTM(\n",
        "            input_size=2*elmo_output_size,\n",
        "            hidden_size=lstm_units,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            proj_size=elmo_output_size\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Linear(2 * elmo_output_size, vocab_size, bias=True)\n",
        "\n",
        "    def embed_input(self, x):\n",
        "        return self.embedding_matrix(x.view(-1, self.n_chars))\n",
        "\n",
        "    def charCNN(self, x):\n",
        "        embedded = torch.transpose(x, 1, 2)\n",
        "\n",
        "        # pass the embedded input through the convolutional layers\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv_output = conv_layer(embedded)\n",
        "            conv_output, _ = torch.max(conv_output, dim=-1)\n",
        "            conv_output = self.conv_activation(conv_output)\n",
        "            conv_outputs.append(conv_output)\n",
        "\n",
        "        # concatenate the conv outputs\n",
        "        token_embedding = torch.cat(conv_outputs, dim=-1)\n",
        "\n",
        "        # pass the conv output through the highway layers\n",
        "        highway_output = token_embedding\n",
        "        for highway_layer in self.highway_layers:\n",
        "            projected_input = highway_layer(highway_output)\n",
        "            linear_part = highway_output\n",
        "\n",
        "            nonlinear_part, gate = projected_input.chunk(2, dim=-1)\n",
        "            nonlinear_part = self.highway_activation(nonlinear_part)\n",
        "            gate = torch.sigmoid(gate)\n",
        "\n",
        "            highway_output = gate * linear_part + (1 - gate) * nonlinear_part\n",
        "        \n",
        "        token_embedding = self.highway_projection(highway_output) \n",
        "\n",
        "        return token_embedding\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        #batch_size = x.size(0)\n",
        "\n",
        "        # embed the input\n",
        "        # in shape: (batch_size, n_tokens, n_chars)\n",
        "        # out shape: (batch_size, n_tokens, n_chars, embedding_dim)\n",
        "        #embedded = self.embedding_matrix(x.view(-1, self.n_chars))\n",
        "        embedded = self.embed_input(x)\n",
        "\n",
        "        # CharCNN\n",
        "        # in shape: (n_tokens, n_chars, embedding_dim)\n",
        "        # out shape: (n_tokens, projection_dim)\n",
        "        token_embedding = self.charCNN(embedded)\n",
        "\n",
        "        # pass the token embedding through the BiLSTM\n",
        "        lstm_output1, (h1_n, c1_n) = self.lstm1(token_embedding)\n",
        "        lstm_output2, (h2_n, c2_n) = self.lstm2(lstm_output1)\n",
        "\n",
        "        out = self.linear(lstm_output2)\n",
        "        \n",
        "        return out.view(-1, self.n_tokens+2, self.vocab_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ELMo(vocab_size=len(vocab), n_tokens=max_num_words, n_chars=max_num_letters).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== EPOCH 0 ===\n",
            "Training loss: 9.611769676208496, accuracy: 0.0\n",
            "Training loss: 9.180383942343973, accuracy: 4991.1875\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [30], line 92\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m     90\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m=== EPOCH \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m ===\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 92\u001b[0m         train_loss \u001b[39m=\u001b[39m train(model, train_iter, optimizer, criterion)\n\u001b[0;32m     93\u001b[0m         valid_loss \u001b[39m=\u001b[39m evaluate(model, test_iter, criterion)\n\u001b[0;32m     95\u001b[0m         \u001b[39mif\u001b[39;00m valid_loss \u001b[39m<\u001b[39m best_valid_loss:\n",
            "Cell \u001b[1;32mIn [30], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[0;32m     26\u001b[0m logits \u001b[39m=\u001b[39m model(char_ids)\n\u001b[0;32m     28\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(vocab)), word_ids\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m---> 29\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     31\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     33\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
            "File \u001b[1;32mc:\\Users\\datapaf\\miniconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\datapaf\\miniconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# train the model and evalutate it with tensorboard\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        word_ids, char_ids = batch\n",
        "        word_ids = word_ids.to(device)\n",
        "        char_ids = char_ids.to(device)\n",
        "\n",
        "        logits = model(char_ids)\n",
        "\n",
        "        loss = criterion(logits.view(-1, len(vocab)), word_ids.view(-1))\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "        # calculate accuracy\n",
        "        preds = torch.argmax(logits, dim=2)\n",
        "        epoch_acc += torch.sum(preds == word_ids).item() / len(word_ids) \n",
        "\n",
        "        \n",
        "        writer.add_scalar('Loss/train', epoch_loss / (i+1), i)\n",
        "        writer.add_scalar('Accuracy/train', epoch_acc / (i+1), i)\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f'Training loss: {epoch_loss / (i+1)}, accuracy: {epoch_acc}')\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            word_ids, char_ids = batch\n",
        "            \n",
        "            word_ids = word_ids.to(device)\n",
        "            char_ids = char_ids.to(device)\n",
        "\n",
        "            logits = model(char_ids)\n",
        "\n",
        "            logits = logits.view(-1, len(vocab))\n",
        "            word_ids = word_ids.view(-1)\n",
        "\n",
        "            loss = criterion(logits, word_ids)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            \n",
        "            # calculate accuracy\n",
        "            preds = torch.argmax(logits, dim=2)\n",
        "            acc = torch.sum(preds == word_ids).item() / len(word_ids)\n",
        "            epoch_acc += acc\n",
        "\n",
        "            writer.add_scalar('Loss/valid', epoch_loss / (i+1), i)\n",
        "            writer.add_scalar('Accuracy/valid', epoch_acc / (i+1), i)\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f'Validation loss: {epoch_loss / (i+1)}, accuracy: {epoch_acc / (i+1)}')\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "N_EPOCHS = 2\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "        \n",
        "        print(f'=== EPOCH {epoch} ===')\n",
        "\n",
        "        train_loss = train(model, train_iter, optimizer, criterion)\n",
        "        valid_loss = evaluate(model, test_iter, criterion)\n",
        "        \n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'model.pt')\n",
        "        \n",
        "        # writer.add_scalar('Loss/train', train_loss, epoch)\n",
        "        # writer.add_scalar('Loss/valid', valid_loss, epoch)\n",
        "    \n",
        "        # print(f'Epoch: {epoch+1:02}')\n",
        "        # print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "        # print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "\n",
        "writer.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train the model\n",
        "from torch import optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "crossentropy = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(2):\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for i, batch in enumerate(train_iter):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        word_ids, char_ids = batch\n",
        "        word_ids = word_ids.to(device)\n",
        "        char_ids = char_ids.to(device)\n",
        "        \n",
        "        logits = model(char_ids)\n",
        "        \n",
        "        loss = crossentropy(logits.view(-1, len(vocab)), word_ids.view(-1))\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % BATCH_SIZE == BATCH_SIZE-1:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss}')\n",
        "            running_loss = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'elmo.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ELMo(\n",
              "  (embedding_matrix): Embedding(16340, 4)\n",
              "  (conv_layers): ModuleList(\n",
              "    (0): Conv1d(4, 4, kernel_size=(1,), stride=(1,))\n",
              "    (1): Conv1d(4, 8, kernel_size=(2,), stride=(1,))\n",
              "    (2): Conv1d(4, 26, kernel_size=(3,), stride=(1,))\n",
              "    (3): Conv1d(4, 32, kernel_size=(4,), stride=(1,))\n",
              "    (4): Conv1d(4, 64, kernel_size=(5,), stride=(1,))\n",
              "  )\n",
              "  (conv_activation): ReLU()\n",
              "  (highway_layers): ModuleList(\n",
              "    (0): Linear(in_features=134, out_features=268, bias=True)\n",
              "    (1): Linear(in_features=134, out_features=268, bias=True)\n",
              "  )\n",
              "  (highway_activation): ReLU()\n",
              "  (highway_projection): Linear(in_features=134, out_features=32, bias=True)\n",
              "  (lstm): LSTM(32, 256, proj_size=32, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (linear): Linear(in_features=64, out_features=16340, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ELMo(vocab_size=len(vocab), n_tokens=max_num_words, n_chars=max_num_letters).to(device)\n",
        "model.load_state_dict(torch.load('elmo.pt'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ4HsuafA5sQ"
      },
      "source": [
        "## Evaluate your embeddings model on IMDB movie reviews dataset (sentiment analysis) \n",
        "[Dataset](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)\n",
        "\n",
        "Preprocess data\n",
        "\n",
        "Disable training for ELMo, it will produce 5 embeddings for each word, add trainable parameters $\\gamma^{task}$ and $s^{task}_j$\n",
        "\n",
        "Don't forget metric plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "IQ_0LTQf81CM"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# read IMDB dataset\n",
        "import pandas as pd\n",
        "\n",
        "imdb = pd.read_csv('IMDB Dataset.csv')\n",
        "imdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filter non-ASCII Strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        One of the other reviewers has mentioned that ...\n",
              "1        A wonderful little production. <br /><br />The...\n",
              "2        I thought this was a wonderful way to spend ti...\n",
              "3        Basically there's a family where a little boy ...\n",
              "4        Petter Mattei's \"Love in the Time of Money\" is...\n",
              "                               ...                        \n",
              "45335    I thought this movie did a down right good job...\n",
              "45336    Bad plot, bad dialogue, bad acting, idiotic di...\n",
              "45337    I am a Catholic taught in parochial elementary...\n",
              "45338    I'm going to have to disagree with the previou...\n",
              "45339    No one expects the Star Trek movies to be high...\n",
              "Name: review, Length: 45340, dtype: object"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews = imdb['review']\n",
        "labels = imdb['sentiment']\n",
        "\n",
        "ascii_review_indices = np.array(list(map(lambda x: x.isascii(), reviews)))\n",
        "ascii_reviews = reviews[ascii_review_indices]\n",
        "ascii_reviews = ascii_reviews.reset_index(drop=True)\n",
        "ascii_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Padded Char Ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([45340, 573, 35])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padded_review_char_ids = torch.full(\n",
        "    size=(len(ascii_reviews), max_num_words + 2, max_num_letters),\n",
        "    fill_value=symbols_vocab['<pad>']\n",
        ")\n",
        "padded_review_char_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "for sent_num, sent in enumerate(ascii_reviews):\n",
        "    tokenized = tokenizer(sent)\n",
        "    for i in range(0, min(len(tokenized), max_num_words) + 2):\n",
        "        if i == 0:\n",
        "            padded_review_char_ids[sent_num, i, 0] = symbols_vocab['<bow>']\n",
        "            padded_review_char_ids[sent_num, i, 1] = symbols_vocab['<bos>']\n",
        "            padded_review_char_ids[sent_num, i, 2] = symbols_vocab['<eow>']\n",
        "            continue\n",
        "        elif i == len(tokenized) + 1:\n",
        "            padded_review_char_ids[sent_num, i, 0] = symbols_vocab['<bow>']\n",
        "            padded_review_char_ids[sent_num, i, 1] = symbols_vocab['<eos>']\n",
        "            padded_review_char_ids[sent_num, i, 2] = symbols_vocab['<eow>']\n",
        "            continue\n",
        "        word = tokenized[i - 1]\n",
        "        for letter_num, letter in enumerate(word):\n",
        "            if letter_num >= max_num_letters:\n",
        "                break\n",
        "            padded_review_char_ids[sent_num, i, letter_num] = symbols_vocab[letter]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = labels[ascii_review_indices]\n",
        "labels = labels.reset_index(drop=True)\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        1\n",
              "1        1\n",
              "2        1\n",
              "3        0\n",
              "4        1\n",
              "        ..\n",
              "45335    1\n",
              "45336    0\n",
              "45337    0\n",
              "45338    0\n",
              "45339    0\n",
              "Name: sentiment, Length: 45340, dtype: int64"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# encode labels with pandas\n",
        "labels = labels.map({'positive': 1, 'negative': 0})\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 1, 1,  ..., 0, 0, 0])"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_tensor = torch.tensor(labels.values)\n",
        "labels_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([45340])"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([45340, 1])"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# reshape labels_tensor to (batch_size, 1)\n",
        "labels_tensor = labels_tensor.view(-1, 1)\n",
        "labels_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [1],\n",
              "        [1],\n",
              "        ...,\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]])"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.TensorDataset at 0x2024579c2e0>"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create dataset from padded_review_char_ids and labels\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "imdb_ds = TensorDataset(padded_review_char_ids, labels_tensor)\n",
        "imdb_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x201f4206520>"
            ]
          },
          "execution_count": 275,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create loader for imdb_ds\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "imdb_dl = DataLoader(imdb_ds, batch_size=16, shuffle=True)\n",
        "imdb_dl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ELMo IMDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {},
      "outputs": [],
      "source": [
        "from unicodedata import bidirectional\n",
        "from torch import nn\n",
        "\n",
        "class ELMoIMDB(ELMo):\n",
        "    \n",
        "    def __init__(self, vocab_size=len(vocab), n_tokens=max_num_words, n_chars=max_num_letters):\n",
        "        super(ELMoIMDB, self).__init__(vocab_size, n_tokens, n_chars)\n",
        "\n",
        "        #self.elmo = ELMo(vocab_size=len(vocab), n_tokens=max_num_words, n_chars=max_num_letters).to(device)\n",
        "        #self.elmo.load_state_dict(torch.load('elmo.pt'))\n",
        "\n",
        "        # freeze model parameters\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.gamma = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "        self.s_0 = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "        self.s_1 = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "        self.s_2 = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "\n",
        "        # create linear layer with 64 output features and relu activation\n",
        "        self.linear = nn.Linear(64, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # create linear layer for classification\n",
        "        self.classifier = nn.Linear(64, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        embedded = model.embed_input(x)\n",
        "        token_embedding = model.charCNN(embedded)\n",
        "        lstm_output1, (h1_n, c1_n) = model.lstm1(token_embedding)\n",
        "        lstm_output2, (h2_n, c2_n) = model.lstm2(lstm_output1)\n",
        "\n",
        "        h_0 = torch.cat((token_embedding, token_embedding), dim=1)\n",
        "\n",
        "        r = self.gamma * (self.s_0 * h_0 + self.s_1 * lstm_output1 + self.s_2 * lstm_output2)\n",
        "\n",
        "        r = r.view(-1, self.n_tokens + 2, 2 * self.elmo_output_size)\n",
        "\n",
        "        out = torch.sum(r, dim=1)\n",
        "\n",
        "        # pass out through linear layer with relu activation\n",
        "        out = self.linear(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        # pass out through classifier\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        return out \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create elmoimdb model\n",
        "elmoimdb = ELMoIMDB().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,    16] loss: 12.102257370948792\n",
            "[1,    32] loss: 11.29083788394928\n",
            "[1,    48] loss: 11.188578069210052\n",
            "[1,    64] loss: 11.170762479305267\n",
            "[1,    80] loss: 11.105431199073792\n",
            "[1,    96] loss: 11.249241352081299\n",
            "[1,   112] loss: 11.259655594825745\n",
            "[1,   128] loss: 11.243346691131592\n",
            "[1,   144] loss: 11.39393413066864\n",
            "[1,   160] loss: 11.189066648483276\n",
            "[1,   176] loss: 11.161707699298859\n",
            "[1,   192] loss: 11.071907043457031\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [298], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     29\u001b[0m \u001b[39m# pass data through model\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m y_hat \u001b[39m=\u001b[39m elmoimdb(x)\n\u001b[0;32m     32\u001b[0m \u001b[39m# calculate loss\u001b[39;00m\n\u001b[0;32m     33\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_hat, y\u001b[39m.\u001b[39mfloat())\n",
            "File \u001b[1;32mc:\\Users\\datapaf\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[1;32mIn [296], line 33\u001b[0m, in \u001b[0;36mELMoIMDB.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m embedded \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39membed_input(x)\n\u001b[0;32m     32\u001b[0m token_embedding \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcharCNN(embedded)\n\u001b[1;32m---> 33\u001b[0m lstm_output1, (h1_n, c1_n) \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mlstm1(token_embedding)\n\u001b[0;32m     34\u001b[0m lstm_output2, (h2_n, c2_n) \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlstm2(lstm_output1)\n\u001b[0;32m     36\u001b[0m h_0 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((token_embedding, token_embedding), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\datapaf\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\datapaf\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    773\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    775\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    776\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    777\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    778\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# train elmoimdb model on imdb dataloader\n",
        "\n",
        "# define loss function\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam(elmoimdb.parameters(), lr=0.001)\n",
        "\n",
        "# train model\n",
        "for epoch in range(1):\n",
        "\n",
        "    # set model to train mode\n",
        "    elmoimdb.train()\n",
        "\n",
        "    # # initialize loss\n",
        "    # epoch_loss = 0\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (x, y) in enumerate(imdb_dl):\n",
        "\n",
        "        # move data to device\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # zero out gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # pass data through model\n",
        "        y_hat = elmoimdb(x)\n",
        "\n",
        "        # calculate loss\n",
        "        loss = loss_fn(y_hat, y.float())\n",
        "\n",
        "        # backpropagate loss\n",
        "        loss.backward()\n",
        "\n",
        "        # update model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # # add loss to epoch loss\n",
        "        # epoch_loss += loss.item()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 16 == 15:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # # calculate average epoch loss\n",
        "    # epoch_loss /= len(imdb_dl)\n",
        "\n",
        "    # # print epoch loss\n",
        "    # print(f'Epoch {epoch} loss: {epoch_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'ELMoIMDB' object has no attribute 'gamma'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [208], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m crossentropy \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m----> 2\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam([elmoimdb\u001b[39m.\u001b[39;49mgamma, elmoimdb\u001b[39m.\u001b[39ms_0, elmoimdb\u001b[39m.\u001b[39ms_1, elmoimdb\u001b[39m.\u001b[39ms_2], lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\datapaf\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1265\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1264\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1265\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1266\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'ELMoIMDB' object has no attribute 'gamma'"
          ]
        }
      ],
      "source": [
        "crossentropy = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam([elmoimdb.gamma, elmoimdb.s_0, elmoimdb.s_1, elmoimdb.s_2], lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Expected input batch_size (1146) to match target batch_size (1).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [204], line 49\u001b[0m\n\u001b[0;32m     43\u001b[0m logits \u001b[39m=\u001b[39m linear(r)\n\u001b[0;32m     45\u001b[0m \u001b[39m#logits = model(char_ids)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[39m#print(r.shape, labels.shape)\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m loss \u001b[39m=\u001b[39m crossentropy(logits, labels)\n\u001b[0;32m     50\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     52\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
            "File \u001b[1;32mc:\\Users\\datapaf\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\datapaf\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
            "File \u001b[1;32mc:\\Users\\datapaf\\miniconda3\\lib\\site-packages\\torch\\nn\\functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
            "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (1146) to match target batch_size (1)."
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = ELMo(vocab_size=len(vocab), n_tokens=max_num_words, n_chars=max_num_letters).to(device)\n",
        "\n",
        "# freeze model parameters\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "gamma = nn.Parameter(torch.randn(1).to(device))\n",
        "s_0 = nn.Parameter(torch.randn(1).to(device))\n",
        "s_1 = nn.Parameter(torch.randn(1).to(device))\n",
        "s_2 = nn.Parameter(torch.randn(1).to(device))\n",
        "\n",
        "# create linear layer for classification\n",
        "linear = nn.Linear(2 * model.elmo_output_size, 1).to(device)\n",
        "\n",
        "crossentropy = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam([gamma, s_0, s_1, s_2], lr=0.001)\n",
        "\n",
        "for epoch in range(2):\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for i, batch in enumerate(imdb_dl):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        char_ids, labels = batch\n",
        "        char_ids = char_ids.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        embedded = model.embed_input(x)\n",
        "        token_embedding = model.charCNN(embedded)\n",
        "        lstm_output1, (h1_n, c1_n) = model.lstm1(token_embedding)\n",
        "        lstm_output2, (h2_n, c2_n) = model.lstm2(lstm_output1)\n",
        "        \n",
        "        h_0 = torch.cat((token_embedding, token_embedding), dim=1)\n",
        "\n",
        "        r = gamma * (s_0 * h_0 + s_1 * lstm_output1 + s_2 * lstm_output2)\n",
        "\n",
        "        logits = linear(r)\n",
        "\n",
        "        #logits = model(char_ids)\n",
        "        \n",
        "        #print(r.shape, labels.shape)\n",
        "\n",
        "        loss = crossentropy(logits, labels)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % BATCH_SIZE == BATCH_SIZE-1:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss}')\n",
        "            running_loss = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKhTvahJBcBI"
      },
      "source": [
        "## Compare the results with BERT embeddings\n",
        "you can choose other bert model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCojr57Zov7t"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "inputs = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "454c98ae2731e865a69a0b883f25a1cfa6b0f63785a62bbc0572ffd435d4c747"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
